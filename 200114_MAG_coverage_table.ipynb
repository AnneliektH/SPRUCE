{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# adapt the bacterial coverage table to a MAG table from a vOTU table\n",
    "# you already have a viral vOTU table that is clean\n",
    "\n",
    "# The coverage of each population genome was calculated as the average of \n",
    "# all of its binned contig coverages, weighting each contig by its length in base pairs\n",
    "df_bin_len = pd.read_csv('200114_contigs_len.csv',sep='\\t')\n",
    "\n",
    "# calculate mean of each length, put info to dict and dict to df\n",
    "df_total_len = pd.DataFrame(df_bin_len.sum().to_dict(),index=[df_bin_len.index.values[-1]])\n",
    "\n",
    "# add column names in the dict dat correspond with the bin names\n",
    "df_total_len.rename(columns=lambda c: str(c))\n",
    "\n",
    "# transpose the dataframe\n",
    "df_total_len = df_total_len.transpose()\n",
    "\n",
    "\n",
    "# add a column with the bin names because they were the index\n",
    "df_total_len ['index_col'] = df_total_len.index \n",
    "\n",
    "# give the columns header names\n",
    "df_total_len.columns = ['total_len', 'bin_name']\n",
    "\n",
    "# add a number index\n",
    "df_total_len = df_total_len.reset_index()\n",
    "\n",
    "#remove the original index that was bin names\n",
    "del df_total_len['index']\n",
    "\n",
    "# normalized by the number of metagenomic reads in each sample, \n",
    "# calculated as described above for the viral OTU table. Only average coverage \n",
    "# values of ≥ 0.25× were retained; lower values were converted to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open all the lengths of the otu's (otu table)\n",
    "df_otu_len = pd.read_csv('200117_map_to_bact_contigs_nofilter.tsv',sep='\\t')\n",
    "\n",
    "#keep only length and column name\n",
    "df_otu_len = df_otu_len[['bact_contig','length']]\n",
    "\n",
    "# change column headers\n",
    "df_otu_len.columns = ['bact_contig', 'length']\n",
    "#len(df_otu_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open the dataframe with all contigs matched to bins\n",
    "# df_bin_otu = pd.read_csv('191112_all_contigs_inbin.csv', sep ='|')\n",
    "\n",
    "# #  clean this file\n",
    "# df_bin_otu.columns = df_bin_otu.columns.str.replace(\".txt\", \"\")\n",
    "# df_bin_otu = df_bin_otu.replace({'>':''}, regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "results =[]\n",
    "bact_contig_list = df_otu_len.contig.tolist()\n",
    "\n",
    "# get all column names from the dataframe\n",
    "columns = list(df_bin_otu.columns)\n",
    "\n",
    "startTime = datetime.now()\n",
    "ci_time = datetime.now()\n",
    "\n",
    "for i in bact_contig_list:\n",
    "    \n",
    "    # apply the get column function, append the results of this functions to the list results\n",
    "    results.append((i, get_column(df_bin_otu, i, columns)))\n",
    "    if len(results) % 1000 == 0:\n",
    "        print len(results)\n",
    "        print \"total_time: \" + str(datetime.now() - startTime)\n",
    "        print \"current time: \" + str(datetime.now() - ci_time)\n",
    "        ci_time = datetime.now()\n",
    "        \n",
    "\n",
    "# make a dataframe from the results\n",
    "df_contig_mag = pd.DataFrame.from_records(results, columns = [\"bact_contig\", \"magbin\"])\n",
    "\n",
    "\n",
    "\n",
    "df_contig_mag.to_csv('bins_matched_to_contigDONTDOTHIS.csv', index=False) \n",
    "\n",
    "len(df_contig_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge all those dataframes:\n",
    "\n",
    "# merge the 2 dataframes\n",
    "#df_otu_bin_len = pd.merge(df_otu_len, df_bin_otu, on='contig', how='outer')\n",
    "\n",
    "#df_otu_bin_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_column\n",
    "def get_column(df, search_value, column_values):\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # create list from row values\n",
    "        list_row = list(row)\n",
    "        \n",
    "        try:\n",
    "            # check if search_value is found in current row\n",
    "            index_value = list_row.index(search_value)\n",
    "            \n",
    "            # if found return associated column \n",
    "            return column_values[index_value]\n",
    "        \n",
    "        # if not found continue search in next row\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # return not found if value is not present in dataframe\n",
    "    return \"not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge all those dataframes so we have contig length, avg length and bin in one df\n",
    "# open the bins match to the contig file:\n",
    "df_bin_otu = pd.read_csv('bins_matched_to_contig.csv', sep =',')\n",
    "\n",
    "# rename the header for the OTU and lenght file\n",
    "df_otu_len.columns = ['bact_contig', 'length']\n",
    "\n",
    "# merge the 2 dataframes on the bacterial contig name\n",
    "df_otu_bin_len = pd.merge(df_otu_len, df_bin_otu, on='bact_contig', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge with all the average lengths from each bin\n",
    "# change mean length column names\n",
    "df_total_len.columns = ['total_len_bin', 'magbin']\n",
    "\n",
    "# clean this file\n",
    "df_total_len.magbin = df_total_len.magbin.str.replace(\".txt.new\", \"\")\n",
    "\n",
    "\n",
    "# merge\n",
    "df_otu_bin_len_mag = pd.merge(df_otu_bin_len, df_total_len, on='magbin', how='outer')\n",
    "\n",
    "# calculate the normalization factor for the reads (= contig_len / total_bin_len)\n",
    "df_otu_bin_len_mag['bin_norm_factor'] =  (df_otu_bin_len_mag['length'] / df_otu_bin_len_mag['total_len_bin'])\n",
    "\n",
    "\n",
    "# len(df_otu_bin_len_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge with the other one (the coverage table)\n",
    "# open up the coverage table so we can add the avg bin lenght to it\n",
    "df_covtab = pd.read_csv('200117_map_to_bact_contigs_nofilter.tsv', sep ='\\t')\n",
    "\n",
    "# make the columns readable\n",
    "df_covtab.columns = df_covtab.columns.str.split('_sortedIndexed.bam').str[0] + ''\n",
    "\n",
    "\n",
    "# remove lengths from the coverage table, otherwise we have col length twice\n",
    "del df_covtab['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge coverage table and the norm factors\n",
    "df_covtab_avg_len = pd.merge(df_covtab, df_otu_bin_len_mag, on='bact_contig', how='outer')\n",
    "\n",
    "# copy the coverage table\n",
    "df_copy = df_covtab_avg_len.copy()\n",
    "\n",
    "# drop certain columns from this df so we don't have them duplicate\n",
    "del df_copy['length']\n",
    "del df_copy['total_len_bin']\n",
    "\n",
    "\n",
    "# multiply all numbers in df with the bin normalization factor for that scaffold\n",
    "df_copy_num = df_copy[df_copy.select_dtypes(include=['number']).columns].mul(df_copy.bin_norm_factor, 0)\n",
    "\n",
    "# put bacterial name and magbin back to it\n",
    "df_copy[df_copy_num.columns] = df_copy_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a new df from df copy, whwre we transpose df_copy\n",
    "df2 = df_copy.set_index('bact_contig').T\n",
    "\n",
    "# # reset the index so that the index is not the sample name\n",
    "df2 = df2.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the index to col_name so that its no longer named bac_contig bc we have to merge on that\n",
    "df2.columns.name = 'col_name'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open normalization_reads for num of reads per dataset\n",
    "df_norm = pd.read_csv('normalization_reads.csv',sep=',')\n",
    "\n",
    "#reset the index of the otu table so that we don't have a problem when merging\n",
    "df2 = df2.reset_index()\n",
    "\n",
    "df2=df2.rename(columns = {'index':'bact_contig'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the 2 dfs so that we have can normalize\n",
    "df_norm_otu = pd.merge(df_norm, df2, on='bact_contig', how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write to file \n",
    "# df_norm_otu.to_csv('norm_factor_inclded.csv', index=False) \n",
    "\n",
    "# del df_norm_otu['level_0']\n",
    "# df_norm_otu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# multiply all numbers in df with the bin normalization factor for that scaffold\n",
    "df_norm_otu_normalized = df_norm_otu[df_norm_otu.select_dtypes(include=['number']).columns].mul(df_norm_otu.norm_factor_reads, 0)\n",
    "\n",
    "# put bacterial name and magbin back to it\n",
    "df_copy[df_copy_num.columns] = df_copy_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_read[df_read.columns] = df_read\n",
    "\n",
    "# df_read\n",
    "\n",
    "#df_norm_otu.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "df_norm_otu2 = df_norm_otu.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did stuff in excel to this table because I couldn't figure it out in pandas\n",
    "# I normalized for number of reads\n",
    "df_norm_otu2.to_csv('200205_norm_factor_incldedTrans.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv made in excel\n",
    "df_normalized = pd.read_csv('200205_bOTU_table_normalized.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all magbibs\n",
    "unique_bins = df_normalized[\"magbin\"].unique()\n",
    "\n",
    "# # values of ≥ 0.25× were retained; lower values were converted to zero\n",
    "# #num = df_normalized._get_numeric_data()\n",
    "\n",
    "# make 0 into NaN for the normalizing\n",
    "df_normalized = df_normalized.replace(0, np.NaN)\n",
    "\n",
    "# calculate mean abundance for every bin\n",
    "df_bin_abundance = df_normalized.groupby(['magbin']).mean()\n",
    "\n",
    "# make nans into zero's again\n",
    "df_bin_abundance = df_bin_abundance.fillna(0)\n",
    "\n",
    "\n",
    "# values of ≥ 0.25× were retained; lower values were converted to zero\n",
    "num = df_bin_abundance._get_numeric_data()\n",
    "num[num < 0.25] = 0\n",
    "\n",
    "# write bin abundance table to csv\n",
    "df_bin_abundance.to_csv('200205_bin_abundances.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
